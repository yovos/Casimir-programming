{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "divided-roommate",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ordered-parcel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/learner/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/learner/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import nltk\n",
    "#from nltk import tokenize\n",
    "#from nltk.corpus import stopwords\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "import ast\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-ambassador",
   "metadata": {},
   "source": [
    "# Get filename from entered title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words(\"english\"))\n",
    "\n",
    "def get_filename_from_title(title):\n",
    "    File_100_Books = open(\"books_dictionary.txt\", \"r\")\n",
    "    Contents_100_Books = File_100_Books.read()\n",
    "    Dictionary_100_Books = ast.literal_eval(Contents_100_Books)\n",
    "    File_100_Books.close()\n",
    "    #print(Dictionary_100_Books[2]['Title'])\n",
    "    for i in range(len(Dictionary_100_Books)):\n",
    "        if Dictionary_100_Books[i]['Title'] == title:\n",
    "            return Dictionary_100_Books[i]['Filename']\n",
    "\n",
    "\n",
    "#print(get_filename_from_title(\"War and Peace\"))\n",
    "Title_entered = input(\"Enter title: \" )\n",
    "filename = get_filename_from_title(Title_entered)\n",
    "#print(filename)\n",
    "\n",
    "#file = open(\"test.txt\", \"r\")\n",
    "if filename is not None:\n",
    "    file = open(filename, \"r\")\n",
    "else:\n",
    "    print(\"Title was not found.\")\n",
    "    exit()\n",
    "    \n",
    "data = file.read()\n",
    "data_wout_symbols = re.sub(r'[^\\w]', ' ', data) #remove symbols\n",
    "words = data_wout_symbols.split() #split text at space\n",
    "sentences = tokenize.sent_tokenize(data)\n",
    "        \n",
    "def get_list_words_from_title():\n",
    "    #print(get_filename_from_title(\"War and Peace\"))\n",
    "    Title_entered = input(\"Enter title: \" )\n",
    "    filename = get_filename_from_title(Title_entered)\n",
    "    #print(filename)\n",
    "    #file = open(\"test.txt\", \"r\")\n",
    "    if filename is not None:\n",
    "        file = open(filename, \"r\")\n",
    "    else:\n",
    "        print(\"Title was not found.\")\n",
    "        exit()\n",
    "    data = file.read()\n",
    "    data_wout_symbols = re.sub(r'[^\\w]', ' ', data) #remove symbols\n",
    "    words = data_wout_symbols.split() #split text at space\n",
    "    return data_wout_symbols, words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-sperm",
   "metadata": {},
   "source": [
    "# Get list of words, count how often they appear and plot rank v frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEGIN data_wout_symbols, words = get_list_words_from_title()\n",
    "\n",
    "# for i in range(len(words)): \n",
    "#     #make all words lowercase\n",
    "#     words[i] = words[i].lower()\n",
    "\n",
    "# Count_of_letter = collections.Counter(data_wout_symbols) #count how often each letter occurs\n",
    "#END Count_of_words = collections.Counter(words) #count how often each word occurs\n",
    "\n",
    "#print(words) #Print all words\n",
    "#print('Number of words:', len(words)) #How many words are there in total in the txt file\n",
    "Count_of_letter = collections.Counter(data_wout_symbols) #count how often each letter occurs\n",
    "Count_of_words = collections.Counter(words) #count how often each word occurs\n",
    "avg_sen_length = len(sentences)/len(words)\n",
    "\n",
    "#print(frequency_letter) #print all letters and how oftern they occur\n",
    "#print(Count_of_words.most_common(5)) #print x most common words\n",
    "#print(Count_of_words.most_common()[-1]) #print word at the end of the list\n",
    "#print(Count_of_words['war'],Count_of_words['peace']) #print frequency of given word\n",
    "\n",
    "def Rank_Frequency_Plot(N):\n",
    "    \"\"\"\n",
    "    Plot of rank v frequency of N most common words in text\n",
    "    \"\"\"\n",
    "    Most_common_words_decreasing = collections.OrderedDict(Count_of_words.most_common(N)) #most_common returns list and we convert it back into an ordered dictionary for the diagram to work\n",
    "    Frequency_common_words = [(i, Count_of_words[i] / len(words) * 100.0) for i,count in Count_of_words.most_common(N)] #Compute with what percentage the words occur\n",
    "    Frequency_common_words_decreasing = collections.OrderedDict(Frequency_common_words) #Make ordered dictionary of most common words and with which percentage they occur\n",
    "    #print(frequency_percentage[:5]) #print the five most common words with percentage \n",
    "\n",
    "    fig, axes = plt.subplots()\n",
    "    axes.set_xscale('log')\n",
    "    axes.set_yscale('log')\n",
    "    axes.set_xlabel(r'Rank', size=15)\n",
    "    axes.set_ylabel(r'Frequency', size=15)\n",
    "    axes.plot(np.arange(0,N,1), Frequency_common_words_decreasing.values())\n",
    "    #list(frequency_percentage_decreasing).index('is') #Position of a given word in list of most common words\n",
    "    #plt.bar(frequency_percentage_decreasing.keys(), frequency_percentage_decreasing.values())\n",
    "    plt.savefig('diagram.png')\n",
    "    \n",
    "#!!!Rank_Frequency_Plot(3000)\n",
    "#Rank_Frequency_Plot(len(Count_of_words))\n",
    "#print(len(Count_of_words)/len(words)) #Number of unique words/Number total words\n",
    "#print('Number of sentences:', len(sentences))\n",
    "\n",
    "\n",
    "Books_dataframe = pd.read_csv(\"Books_Dataframe.csv\") \n",
    "#print(Books_dataframe)\n",
    "for i in range(100):\n",
    "    print(Books_dataframe.iloc[i,5])\n",
    "#Add all the numbers to the existing dataframe by first storing them in lists and then adding the lists as new columns to dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
