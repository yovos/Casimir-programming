{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chief-flood",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "impressive-remove",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/learner/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "import ast\n",
    "import pandas as pd\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-rebate",
   "metadata": {},
   "source": [
    "# Get filename and list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "numerical-python",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6ccdf64ddda5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_filename_from_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mFile_100_Books\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"books_dictionary.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mContents_100_Books\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFile_100_Books\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "stop_words=set(stopwords.words(\"english\"))\n",
    "\n",
    "def get_filename_from_title(title):\n",
    "    \"\"\"\n",
    "    Gets the filename from the title that is passed as an argument. Returns filename if the title can be found\n",
    "    \"\"\"\n",
    "    File_100_Books = open(\"books_dictionary.txt\", \"r\")\n",
    "    Contents_100_Books = File_100_Books.read()\n",
    "    Dictionary_100_Books = ast.literal_eval(Contents_100_Books)\n",
    "    File_100_Books.close()\n",
    "    #print(Dictionary_100_Books[2]['Title'])\n",
    "    for i in range(len(Dictionary_100_Books)):\n",
    "        if Dictionary_100_Books[i]['Title'] == title:\n",
    "            return Dictionary_100_Books[i]['Filename']\n",
    "\n",
    "def get_list_words_from_title():\n",
    "    \"\"\"\n",
    "    Prompt asks to enter title and returns a list of data without symbols as well as the list of words for this title\n",
    "    \"\"\"\n",
    "    #print(get_filename_from_title(\"War and Peace\"))\n",
    "    Title_entered = input(\"Enter title: \" )\n",
    "    filename = get_filename_from_title(Title_entered)\n",
    "    #print(filename)\n",
    "    #file = open(\"test.txt\", \"r\")\n",
    "    if filename is not None:\n",
    "        file = open(filename, \"r\")\n",
    "    else:\n",
    "        print(\"Title was not found.\")\n",
    "        exit()  \n",
    "    data = file.read()\n",
    "    data_wout_symbols = re.sub(r'[^\\w]', ' ', data) #remove symbols\n",
    "    words = data_wout_symbols.split() #split text at space\n",
    "    sentences = tokenize.sent_tokenize(data)\n",
    "    return data_wout_symbols, words, sentences\n",
    "\n",
    "def get_list_words_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Returns list of data without symbols and list of words for argument that is filename\n",
    "    \"\"\"\n",
    "    file = open(filename, \"r\")\n",
    "    data = file.read()\n",
    "    data_wout_symbols = re.sub(r'[^\\w]', ' ', data) #remove symbols\n",
    "    words = data_wout_symbols.split() #split text at space\n",
    "    return data_wout_symbols, words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-hurricane",
   "metadata": {},
   "source": [
    "# Get list of words, count how often they appear and plot rank v frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "senior-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rank_Frequency_Plot(Count_of_words,N):\n",
    "    \"\"\"\n",
    "    Plot of rank v frequency of N most common words in text.\n",
    "    Count_of_words: ordered dictionary of how often a word occurs\n",
    "    N: N most common words used for figure\n",
    "    \"\"\"\n",
    "    Most_common_words_decreasing = collections.OrderedDict(Count_of_words.most_common(N)) #most_common returns list and we convert it back into an ordered dictionary for the diagram to work\n",
    "    Frequency_common_words = [(i, Count_of_words[i] / len(words) * 100.0) for i,count in Count_of_words.most_common(N)] #Compute with what percentage the words occur\n",
    "    Frequency_common_words_decreasing = collections.OrderedDict(Frequency_common_words) #Make ordered dictionary of most common words and with which percentage they occur\n",
    "    #print(frequency_percentage[:5]) #print the five most common words with percentage \n",
    "    axes.set_xscale('log')\n",
    "    axes.set_yscale('log')\n",
    "    axes.set_xlabel(r'Rank', size=15)\n",
    "    axes.set_ylabel(r'Frequency', size=15)\n",
    "    axes.plot(np.arange(0,N,1), Frequency_common_words_decreasing.values())\n",
    "\n",
    "def stats_for_one_book():\n",
    "    \"\"\"\n",
    "    Asks for a title and returns some statistics as well as a Rank v Frequency plot\n",
    "    \"\"\"\n",
    "    data_wout_symbols, words, sentences = get_list_words_from_title()\n",
    "    for i in range(len(words)): \n",
    "        #make all words lowercase\n",
    "        words[i] = words[i].lower()\n",
    "    Count_of_letter = collections.Counter(data_wout_symbols) #count how often each letter occurs\n",
    "    Count_of_words = collections.Counter(words) #count how often each word occurs\n",
    "    #print(words) #Print all words\n",
    "    print('Number of words:', len(words)) #How many words are there in total in the txt file\n",
    "    Count_of_letter = collections.Counter(data_wout_symbols) #count how often each letter occurs\n",
    "    Count_of_words = collections.Counter(words) #count how often each word occurs\n",
    "    avg_sen_length = len(sentences)/len(words)\n",
    "    #print(frequency_letter) #print all letters and how oftern they occur\n",
    "    print(Count_of_words.most_common(5)) #print x most common words\n",
    "    print(Count_of_words.most_common()[-1]) #print word at the end of the list\n",
    "    #print(Count_of_words['war']) #print frequency of given word\n",
    "    print(len(Count_of_words)/len(words)) #Number of unique words/Number total words\n",
    "    print('Number of sentences:', len(sentences))\n",
    "    fig, axes = plt.subplots()\n",
    "    Rank_Frequency_Plot(3000)\n",
    "    #Rank_Frequency_Plot(len(Count_of_words))\n",
    "    #list(frequency_percentage_decreasing).index('is') #Position of a given word in list of most common words\n",
    "    #plt.bar(frequency_percentage_decreasing.keys(), frequency_percentage_decreasing.values())\n",
    "    plt.savefig('diagram_one.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-mistake",
   "metadata": {},
   "source": [
    "# Add statistics to all books in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stats_All_Books():\n",
    "    \"\"\"\n",
    "    Add statistics (Number of words, most common words, ratio unique words/total words) for all books in dataframe as new columns to dataframe and plot rank v frequency for all books\n",
    "    \"\"\"\n",
    "    Books_dataframe = pd.read_csv(\"Books_Dataframe.csv\")  #read all books from csv into panda dataframe\n",
    "    #list_number_of_words = []\n",
    "    #most_common_letters = []\n",
    "    #most_common_words = []\n",
    "    #most_diverse = []\n",
    "    list_number_of_words , most_common_letters , most_common_words , most_diverse = ([], ) * 4 #Create four empty lists, Mulitplication applied to list duplicates list 4 times\n",
    "    fig, axes = plt.subplots()\n",
    "    for i in range(100):\n",
    "        #go through all 100 books, get filename from dataframe. If the file exists, get words, make lowecase and append stats to empty lists created above. Create rank frequency  plot for 500 most common words\n",
    "        #print(Books_dataframe.iloc[i,5])\n",
    "        filename = Books_dataframe.iloc[i,5]\n",
    "        if os.path.exists(filename):\n",
    "            data_wout_symbols, words = get_list_words_from_filename(filename)\n",
    "            for j in range(len(words)):\n",
    "                words[j] = words[j].lower()\n",
    "            Count_of_letter = collections.Counter(data_wout_symbols) #count how often each letter occurs\n",
    "            Count_of_words = collections.Counter(words) #count how often each word occurs\n",
    "            list_number_of_words.append(len(words))\n",
    "            most_common_letters.append(Count_of_letter.most_common(2))\n",
    "            most_common_words.append(list(collections.OrderedDict(Count_of_words.most_common(2)).keys()))\n",
    "            most_diverse.append(len(Count_of_words)/len(words))\n",
    "            Rank_Frequency_Plot(Count_of_words,500)\n",
    "        else:\n",
    "            list_number_of_words.append(\"File not found\")\n",
    "            most_common_words.append(\"File not found\")\n",
    "            most_common_letters.append(\"File not found\")\n",
    "            most_diverse.append(0)\n",
    "    #Now add lists as new columns to dataframe \n",
    "    Books_dataframe['Total Number Words'] = list_number_of_words\n",
    "    #Books_dataframe['Two Most Common Letters'] = most_common_letters\n",
    "    Books_dataframe['Two Most Common Words'] = most_common_words\n",
    "    Books_dataframe['Ratio of Unique and Total Words'] = most_diverse\n",
    "    Books_dataframe.to_csv(r'Books_w_stats.csv', index = False)\n",
    "    max_index = pd.to_numeric(Books_dataframe['Ratio of Unique and Total Words']).idxmax() #Get index of most diverse work\n",
    "    print(Books_dataframe.iloc[max_index,1]) #print name of books\n",
    "    plt.savefig('diagram_many.png') #save figure of rank v frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-fever",
   "metadata": {},
   "source": [
    "# Calculate average sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read a .csv file where a pandas dataframe with all the book info is stored.\n",
    "Books_dataframe = pd.read_csv(\"Books_Dataframe.csv\") \n",
    "\n",
    "#Get a list of all the book filenames\n",
    "book_filenames = Books_dataframe[\"Filename\"]\n",
    "\n",
    "#Get a list of all the book titles\n",
    "book_titles = Books_dataframe[\"Title\"]\n",
    "\n",
    "#Create an empty list to which we append the average sentence length of each book\n",
    "avg_sentence_length = []\n",
    "\n",
    "#Loop through all the books\n",
    "for filename in book_filenames:\n",
    "    \n",
    "    #Try to load the file, if it does not exist add an average sentence length of 0 and continue\n",
    "    try:\n",
    "        file = open(filename, \"r\") #Open file\n",
    "    except FileNotFoundError:\n",
    "        avg_sentence_length.append(0) #Set average sentence length to 0 if file does not exist\n",
    "        continue\n",
    "    \n",
    "    #Obtain file content as string\n",
    "    data = file.read()\n",
    "    \n",
    "    #Obtain all the sentences using tlk tokenize\n",
    "    sentences = tokenize.sent_tokenize(data)\n",
    "    \n",
    "    #\n",
    "    data_wout_symbols = re.sub(r'[^\\w]', ' ', data) #remove symbols\n",
    "    words = data_wout_symbols.split() #split text at space\n",
    "    \n",
    "    avg_sentence_length.append(len(words)/len(sentences))\n",
    "\n",
    "avg_sentence_length_sorted = np.sort(avg_sentence_length)    \n",
    "book_titles_sorted = book_titles[np.argsort(avg_sentence_length)]    \n",
    "    \n",
    "fig, ax = plt.subplots(1, figsize=(10,10))\n",
    "ax.bar(book_titles_sorted, avg_sentence_length_sorted)\n",
    "ax.set_ylable()\n",
    "plt.xticks(rotation = 'vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-flavor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
